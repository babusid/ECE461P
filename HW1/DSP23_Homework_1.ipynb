{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QDMxPNTM-8Ew"
      },
      "source": [
        "## EE 461P: Data Science Principles  \n",
        "### Assignment 1  \n",
        "### Total points: 75\n",
        "### Due: Tuesday, January 31, 2023, submitted via Canvas by 11:59 pm  \n",
        "\n",
        "Your homework should be written in a **Jupyter notebook**. You may work in groups of two if you wish. Only one student per team needs to submit the assignment on Canvas.  But be sure to include name and UT eID for both students.  Homework groups will be created and managed through Canvas, so please do not arbitrarily change your homework group. If you do change, let the TAs know.\n",
        "\n",
        "Also, please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting. (%matplotlib inline)\n",
        "\n",
        "### Name(s) and EID(s):\n",
        "1. Sidharth Babu, SNB2593\n",
        "2. Laith Altarabishi, LA26744"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2l4ZpGDS0bVI"
      },
      "source": [
        "# Question 1 (5 points)\n",
        "\n",
        "Read [this](https://www.covid-datascience.com/post/israeli-data-how-can-efficacy-vs-severe-disease-be-strong-when-60-of-hospitalized-are-vaccinated) article that talks about the possibility of vaccines being uneffective in Israel since nearly 60% of severe COVID-19 hospitalization in Israel were vaccinated people. Use Simpson's Paradox to briefly explain if this claim holds true.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qaijrS9q8_go"
      },
      "source": [
        "While it's true that nearly 60% of hospitilizations in Israel were vaccinated people, this observation is largely misleading due to the fact that there are a large number of confounding factors and dependent conditions that underly this data. Namely it doesn't address the fact the elderly(>50) are orders of magnitude more susceptible to having severe cases of COVID-19 than those who are younger(<50). This statisitic doesn't stratify the population of Israel by age, or look at the efficacy of the vaccine from a dataset where we consider the severe cases of the COVID-19 in a normalized count. \n",
        "\n",
        "In this article we see that both normalizing our severe cases, and stratifying our data by age we see significantly higher efficacy rates amongst both the elderly(85.2%) and the youth(91.8%) despite the fact that when we combine both groups together, we get significanly lower efficacy(67.5%). The reason for this is because the elderly were not only largely more vaccinated as a stratified age group(90.4% vs 73%) - but they were also more at risk of having a severe case of COVID in comparison to the youth. This creates a confounding situation that can effect the larger pool of data when we look at the population of Isreal as a whole, and gives us paradoxical results that may not characterize what's actually happening in our data. \n",
        "\n",
        "Thus, when clearly eliminating the confounding effect of age and looking at a stratified and normalized dataset, we see that the vaccine actually has a pretty high efficacy rate across all age groups and ranges - making a solid case for the vaccine actually being an effective countermeasure to COVID-19. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNBbUfy9Fxqg"
      },
      "source": [
        "# Question 2 (10 points)\n",
        "\n",
        "100 students in the previous offering of this class were asked if they wanted to form their own groups for the course project or have the instructor randomize the groups. They reported their preferences by entering Yes or No in the survey. We use 0 to represent preferring their own groups and 1 to represent randomized groups. A random sample of 20 students yielded the following preferences:\n",
        "\n",
        "$$1 0 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1$$\n",
        "\n",
        "These choices are assumed to arise by independent and identically distributed (i.i.d.) sampling from the following distribution and if the unknown parameter $q$ can be estimated, then we can provide more insights about the students' preference regrading the project groups.\n",
        "\n",
        "$$\n",
        "\\begin{equation}\n",
        "\\nonumber P(x) = \\left\\{\n",
        "\\begin{array}{l l}\n",
        "    q& \\quad \\text{for  } x=0\\\\\n",
        "1-q & \\quad \\text{for } x=1\n",
        "\\end{array} \\right.\n",
        "\\end{equation}\n",
        "$$\n",
        "\n",
        "Based on the definitions given above, identify the likelihood function and derive the **maximum likelihood estimator** of $q$. Using the given sample, find a maximum likelihood estimate of $q$ as well."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ_Kz4VN9Dus"
      },
      "source": [
        "# Answer 2\n",
        "L(θ) = ∏ f(xi|θ) = ∏ q^1-xi * (1-q)^xi "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHBVQzeVPs02"
      },
      "source": [
        "# Question 3 (5+5 points)\n",
        "\n",
        "a) Briefly explain what you understand by an estimator of a numeric quantity being unbiased? Show that the MLE for the variance of a Gaussian is biased.\n",
        "\n",
        "b) Suppose the mean of the Gaussian distribution, $\\mu$. So given a data set assumed to be obtained by sampling i.i.d from this Gaussian, your job is to obtain the MLE for the unknown variance. Derive the equation for this estimate and show that it is unbiased."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UovxZfi8Pt7N"
      },
      "source": [
        "# Answer 3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqV_7myxCupC"
      },
      "source": [
        "# Question 4 (5+5 points)\n",
        "\n",
        "a) What is multicollinearity in the context of linear regression and why is it problematic?\n",
        "\n",
        "b) How do you diagnose and fix multicollinearity?\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "U2a5wCF9C7Vw"
      },
      "source": [
        "a) Multicollinearity refers to the situation where two or more independent variables that contribute to our linear regression model are correlated with one another - meaning that we can effectively predict one independent variable as a function of other independent variables. This is problematic as this will create instability in our model since we know that in our linear equations for regression, we try to compute beta values that represent the isolated rate of change in our dependent variable with respect to each independent variable - fixing everything else. However, if our independent variables are correlated with one another - this creates complications since our model won't be able to accurately estimate what beta values accurately map our independent variables to our dependent variable since we won't be able to isolate each independent variable without possibly effecting other variables in a significant way.\n",
        "\n",
        "b) We could diagnose multicollinearity by computing the correlation matrix between all of our independent variables, and evaluating which variables have the most correlation and whether or not the correlation value is too high. We could also evaluate the standard error of our data, and see if the error is very high with some of the independent variables. To fix this problem, there a few solutions that we could explore. We could use PCA to reduce the dimensionality of our data, or remove variables that are highly correlated with one another from the dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8M2y37dATTO"
      },
      "source": [
        "# Question 5 : Regression (40 points)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIeme-FoAWxH"
      },
      "source": [
        "### 5.1 Generate Data (5 points)\n",
        "Generate a synthetic regression dataset using make_regression from [sklearn.datasets](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html) with the following characteristics :\n",
        "n_samples = 20000, n_features = 20, n_informative = 15, n_targets = 1, coef = True and random_state = 42, bias = True, noise = 0.1.\n",
        "\n",
        "**Reading Assignment** : Read about how this data is generated and the affect of the above mentioned parameters on the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYOT8DJcAX7q",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI4XeUtjAYgc"
      },
      "source": [
        "### 5.2 Perform Regression (10 points)\n",
        "a) Divide the above obtained data into a train/test split by using 20% of the data for testing. Then train a linear regression model using Ordinary Least Squares method from [sklearn](https://scikit-learn.org/stable/modules/linear_model.html). \n",
        "\n",
        "b) Evaluate the trained model using Mean Squared Error on both train and test datasets and report the performance. \n",
        "\n",
        "c) Also, print the coefficients and bias obtained after the fit and compare them with the coefficients and bias that were used for generating the data in 5.1. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0joZZhB_AbR3",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgzF7qSSAbf5"
      },
      "source": [
        "### 5.3 Residuals (5 points)\n",
        "a) Compute the residuals (difference between predicted and original values)  of the trained model on the test data. Compute and show the mean and variance of the residuals. \n",
        "\n",
        "b) Scatter plot the residuals along with true predictions and observe how are the residuals distributed.\n",
        "\n",
        "(BONUS) How do the above observations relate to one of the asumptions behind the MLR model? (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xujyYrCEAd1x",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJPQpojJAeAa"
      },
      "source": [
        "### 5.4 Lasso and Ridge Regression (10 points)\n",
        "\n",
        "a) Run Lasso and Ridge regression on the data generated in 5.1 by varying the parameter alpha from 10^-3 to 10^3. For each value of the alpha, store the train error (MSE), test error (MSE), and norm of the coefficient vector using [numpy.linalg.norm](https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html).\n",
        "\n",
        "b) Plot the train error, test error and the norm of the coefficient vector with increasing alpha and note what you observe. Use one plot for train error and test error and another for the norm.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDT3C9W7j4QW",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWbeD15fRXdl"
      },
      "source": [
        "### 5.5 Real-world Regression Problem (10 points)\n",
        "\n",
        "The dataset in the file ecommerce_dataset.csv is for an ecommerce business trying to predict the annual amount spent by each customer. Use Lasso and Ridge regression on the set of independent variables {Average Session Length, Time on App, Time on Website, Length of Membership}  to predict the dependent variable **Yearly Amount Spent**. Vary the value of alpha in the range 10^-6 to 10^5 and do 5-fold cross-validation using sklearn's KFold to find the value of alpha that gives best performance as measured using MSE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snk9yvieSX5d",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "QDMxPNTM-8Ew",
        "NNBbUfy9Fxqg",
        "yHBVQzeVPs02"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
